---

### Variables specific for webops customer

#### SCRAPY VARIABLES ####
scrapy_redis_node: "{{ groups['redis-master-node'][1] }}"

#### DOCKER VARIABLES ####
docker_repo_user: istuser
docker_repo_pwd: "{{ vault_repo_pwd }}"

#### AWS Customize Variables ####
data_volume: /dev/xvdf

#### ELASTICSEARCH VARIABLES ####
elasticsearch_network_http_port: 9243

#### ZOOKEEPER VARS ####
zookeeper_maxClientCnxns: 600

#### KAFKA VARS
# Internap slaves have 6 data disks, striping data across them.
kafka_data_log_dir: 
   - /data/kafka/topic-logs

kafka_data_dir: 
   - /data/kafka

# According to Apache Docs, num io threads should be at least equal number of disks.
kafka_num_io_threads: 2

kafka_heap: 8G

# Retain for 1 week by default
kafka_log_retention_hours: 168
kafka_num_partitions: 8
kafka_replication_factor: 2

#### STORM VARS ####
storm_version: 0.10.0
storm_worker_ports: [6701, 6702, 6703, 6704, 6705, 6706, 6707, 6708, 6709, 6710, 6711, 6712, 6713, 6714, 6715, 6716, 6717, 6718, 6719, 6720, 6721, 6722, 6723, 6724, 6725, 6726, 6727, 6728, 6729, 6730, 6731, 6732, 6733, 6734, 6735, 6736, 6737, 6738, 6739, 6740, 6741, 6742, 6743, 6744, 6745, 6746, 6747, 6748]

storm_worker_extra_config:
    worker.childopts: "-Xmx1280m -XX:PermSize=128m -XX:MaxPermSize=256m -Xms256m -XX:+UseConcMarkSweepGC -Dcom.sun.management.jmxremote"
    supervisor.worker.timeout.secs: 60

storm_nimbus_extra_config:
    nimbus.childopts: "-Xmx1024m"
    nimbus.thrift.max_buffer_size: 4194304

#### Connecting Logstash to ES Cloud ####
logstash_credentials: true
logstash_es_user: "admin"
logstash_es_pwd: "{{ vault_logstash_es_pwd }}"